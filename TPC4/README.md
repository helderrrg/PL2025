# PL 2024/25 - TPC3

## üìñ Resumo
Para resolver o problema de construir um analisador l√©xico para uma linguagem de query, utilizei o m√≥dulo `ply.lex` em Python. O objetivo era criar um tokenizer capaz de processar consultas semelhantes √†s utilizadas em certas linguagens de query, reconhecendo palavras reservadas, identificadores, strings, s√≠mbolos e n√∫meros. Segue a descri√ß√£o da resolu√ß√£o:

- **Palavras Reservadas:** Utilizei um dicion√°rio para mapear palavras reservadas como `SELECT`, `WHERE`, `LIMIT` e outras. Durante o processamento de identificadores, verifico se o valor est√° no dicion√°rio para atribuir o tipo correto.

- **Identificadores:** Aceitam caracteres alfanum√©ricos e colons (`:`), adequados para IRIs (ex: `dbo:MusicalArtist`).

- **Strings:** A regex `r'"[^"]*"(?:@[a-zA-Z]+)?'` captura strings entre aspas duplas, permitindo tags de idioma opcionais (ex: `@en`).

- **N√∫meros:** Capturados como sequ√™ncias de d√≠gitos e convertidos para inteiros.

- **S√≠mbolos:** Definidos por regex simples, como `.` (ponto), `?` (interroga√ß√£o), `=` (igual), `{`, `}`.

- **Coment√°rios:** Linhas come√ßando com `#` s√£o ignoradas.

- **Rastreamento de Linhas:** A regra `t_newline` atualiza o contador de linhas (`lineno`) para facilitar depura√ß√£o.

## üìÇ Resultados
Segue a localiza√ß√£o dos ficheiros produzidos:
- [`analisadorLexico.py`](analisadorLexico.py) - [Ficheiro com c√≥digo fonte]

## Autor  

- **Nome:** H√©lder Ricardo Ribeiro Gomes 
- **N√∫mero de aluno:** A104100
---